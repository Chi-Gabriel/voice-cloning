services:
  comfyui:
    image: yanwk/comfyui-boot:cu121  # NVIDIA CUDA 12.1 Image
    container_name: comfyui-production
    restart: unless-stopped
    network_mode: host  # Simplifies port mapping for the API
    
    # ENVIRONMENT VARIABLES
    environment:
      - CLI_ARGS=--listen 0.0.0.0 --port 8188 --preview-method auto
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    
    # VOLUMES: This maps your hard drive into the container
    volumes:
      # Map the "storage" folder to the container's internal storage
      - ./storage/models:/comfyui/models
      - ./storage/output:/comfyui/output
      - ./storage/user:/comfyui/user
      - ./storage/custom_nodes:/comfyui/custom_nodes
      
      # Map the scripts folder
      - ./scripts:/home/runner/scripts

    # GPU RESERVATION (Critical for RTX A4000)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  qwen-api:
    build: 
      context: .
      dockerfile: qwen_tts_service/Dockerfile
    container_name: qwen-tts-api
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # Shared path inside container
      - MODEL_ROOT=/app/models/Qwen3-TTS
      - DEVICE=cuda:0
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      - API_KEY=${API_KEY:-}
    volumes:
      # Mount the same models directory
      - ./storage/models:/app/models
      # Expose temp file registry to host
      - ./storage/temp_audio:/tmp/tts_files
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]